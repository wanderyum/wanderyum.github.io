<!DOCTYPE html>
<html class="nojs" lang="en" dir="ltr">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Python爬虫初探--爬取豆瓣电影TOP250 – Manfredo的主页</title>
<meta name="description" content="必备知识 1. requests库 基本用法: import requests resp = requests.">
<meta name="created" content="2020-02-24T21:40:35+0800">
<meta name="modified" content="2020-02-24T21:40:35+0800">

<meta name="contact" content="wangzhiyu0471@gamil.com">
<meta property="og:site_name" content="Manfredo的主页">
<meta property="og:title" content="Python爬虫初探--爬取豆瓣电影TOP250">
<meta property="og:url" content="https://wanderyum.github.io/blogs/python%E7%88%AC%E8%99%AB%E5%88%9D%E6%8E%A2/">
<meta property="og:type" content="article">

<meta name="generator" content="Hugo 0.64.1" />
<meta name="msapplication-TileColor" content="#00FF00">
<meta name="theme-color" content="#00FF00">


<link rel="canonical" href="https://wanderyum.github.io/blogs/python%E7%88%AC%E8%99%AB%E5%88%9D%E6%8E%A2/">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#000000">
<link rel="manifest" href="/site.webmanifest">

<link rel="stylesheet" href="/css/styles.9a3856451d3f4911845551d6f046455bd8cbf120441071c76e7438ba3ac163e1.css">
<link rel="stylesheet" href="/css/print.27fc184f8670f41a2690985390779e7b20335a8fadff8fa015cf9417ffe50c36.css" media="print">

<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "WebPage",
    "headline": "Python爬虫初探--爬取豆瓣电影TOP250",
    "datePublished": "2020-02-24T21:40:35+08:00",
    "dateModified": "2020-02-24T21:40:35+08:00",
    "url" : "https://wanderyum.github.io/blogs/python%E7%88%AC%E8%99%AB%E5%88%9D%E6%8E%A2/",
    "description": "必备知识 1. requests库 基本用法: import requests resp = requests.",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://wanderyum.github.io/"
    },
    "publisher": {
      "@type": "Organization",
      "name": "Manfredo的主页",
      "url": "https://wanderyum.github.io/"
    }
  }
</script>

<script defer src="/js/umbrella.min.b426107371d121c9a56a27aac9e9058ff592a021e2f4c3c94827fe70920d3cbb.js"></script>
<script defer src="/js/script.min.8e4d91ebe0d9226621e408b7205bd7b009e4935608e4b29c4275116490cc836d.js"></script>


</head>

<body>
<div class="page layout__page layout__sidebar-second">
<header class="header layout__header">
<a href="/" title="Home" rel="home" class="header__logo"><img src="/images/logo.png" alt="Home" class="header__logo-image"></a>
<h1 class="header__site-name">
<a href="/" title="Home" class="header__site-link" rel="home"><span>Manfredo的主页</span></a>
</h1>
<div class="region header__region">
</div>
</header>

<nav class="main-menu layout__navigation">
<h2 class="visually-hidden">Main menu</h2>
<ul class="navbar">
<li><a href="/">走马观花</a></li>
<li><a href="/codes/">滴水穿石</a></li>
<li><a href="/blogs/">千虑一得</a></li>
<li><a href="/research/">砥志研思</a></li>
<li><a href="/cv/">何许人也</a></li>
</ul>
</nav>


<main class="main layout__main">
<article class="section-blogs single-view">
<header>
<h1 class="title title-submitted">Python爬虫初探--爬取豆瓣电影TOP250</h1>
<div class="submitted">
<time class="modified-date" datetime="2020-02-24T21:40:35&#43;08:00">24 February, 2020</time>
</div>
</header>
<div class="content">
<h3 id="必备知识-">必备知识</h3>
<h4 id="1-requests库-">1. requests库</h4>
<p>基本用法:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> requests
resp <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">https://www.baidu.com</span><span style="color:#e6db74">&#39;</span>)
</code></pre></div><p>所得到的resp是一个requests.models.Response对象，需要用.text来获取目标网页的.html源文件:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">html <span style="color:#f92672">=</span> resp<span style="color:#f92672">.</span>text
</code></pre></div><p>用这种方法可以获取百度的返回结果，但是用这样的方法来获取豆瓣电影TOP250(<a href="https://movie.douban.com/top250">movie.douban.com/top250</a>)会得到空的结果。</p>
<p>这里貌似是因为豆瓣要求访问的设备必须告知其所用浏览器型号，也就是要告知User-Agent类型。</p>
<p><strong>查看User-Agent类型方法</strong>
以chrome浏览器为例，地址栏输入<code>chrome://version/</code>，其中用户代理那一行就是。<br>
例如这里查到的是<code>Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.116 Safari/537.36</code></p>
<p>于是就可以采用下面带header的用法:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> requests
headers <span style="color:#f92672">=</span> {<span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">User-Agent</span><span style="color:#e6db74">&#34;</span>: <span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.116 Safari/537.36</span><span style="color:#e6db74">&#34;</span>}
resp <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">https://movie.douban.com/top250</span><span style="color:#e6db74">&#39;</span>, headers<span style="color:#f92672">=</span>headers)
html <span style="color:#f92672">=</span> resp<span style="color:#f92672">.</span>text
</code></pre></div><p>tips:<br>
<del>1. 由于这里用的是Win10+Python3，所取得的网页是utf-8编码的，而这里的Python的<code>print</code>函数输出默认编码为gbk,所以遇到中文会报错。</del> 这个问题只在用notepad++时遇到，用vscode后没有这个问题了。<br>
2. 因为编码问题，如果要保存结果的话需要指定编码格式为utf-8:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">htm.txt</span><span style="color:#e6db74">&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">w</span><span style="color:#e6db74">&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">utf-8</span><span style="color:#e6db74">&#39;</span>) <span style="color:#66d9ef">as</span> f:
    <span style="color:#66d9ef">print</span>(html, file<span style="color:#f92672">=</span>f)
</code></pre></div><h4 id="2-bs4库-">2. bs4库</h4>
<p>bs4即Beautifulsoup库，用来解析所得到的.html内容。</p>
<p>基本用法:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> bs4 <span style="color:#f92672">import</span> BeautifulSoup
soup <span style="color:#f92672">=</span> BeautifulSoup(html, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">html.parser</span><span style="color:#e6db74">&#39;</span>)   <span style="color:#75715e"># 使用默认解析器解析</span>
tars <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>find_all(class_<span style="color:#f92672">=</span><span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">info</span><span style="color:#e6db74">&#39;</span>)         <span style="color:#75715e"># 在soup里面找class==&#39;info&#39;的所有内容, 返回列表</span>
tar <span style="color:#f92672">=</span> tars[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>find(class_<span style="color:#f92672">=</span><span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">title</span><span style="color:#e6db74">&#39;</span>)          <span style="color:#75715e"># 在前面列表第一项中找到第一个class==&#39;title&#39;的项并返回</span>
content <span style="color:#f92672">=</span> tar<span style="color:#f92672">.</span>find(<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">p</span><span style="color:#e6db74">&#39;</span>)<span style="color:#f92672">.</span>get_text()          <span style="color:#75715e"># 在tar中找第一个&lt;p&gt;中的内容,  返回内容字符串</span>
</code></pre></div><p>tips:</p>
<ol>
<li>这里本来应该是<code>class='info'</code>, 但由于<code>class</code>是python的关键字, 所以所有的<code>class</code>用<code>class_</code>来表示。</li>
</ol>
<h3 id="初步尝试-">初步尝试</h3>
<p>我们先尝试获取豆瓣电影TOP250第一页的html内容并保存分析:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">url <span style="color:#f92672">=</span> <span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">https://movie.douban.com/top250</span><span style="color:#e6db74">&#34;</span>
headers <span style="color:#f92672">=</span> {<span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">User-Agent</span><span style="color:#e6db74">&#34;</span>: <span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.116 Safari/537.36</span><span style="color:#e6db74">&#34;</span>}
resp <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(url, headers<span style="color:#f92672">=</span>headers)
<span style="color:#66d9ef">with</span> open(<span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">html.txt</span><span style="color:#e6db74">&#39;</span>, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">w</span><span style="color:#e6db74">&#39;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">utf-8</span><span style="color:#e6db74">&#39;</span>) <span style="color:#66d9ef">as</span> f:
    <span style="color:#66d9ef">print</span>(resp<span style="color:#f92672">.</span>text, file<span style="color:#f92672">=</span>f)
</code></pre></div><p>用记事本打开保存的结果并观察, 我们发现我们要的内容其实是在<code>&lt;div class=&quot;info&quot;&gt;</code>和<code>&lt;/div&gt;</code>中的内容。于是我们用bs4进行提取:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">soup <span style="color:#f92672">=</span> BeautifulSoup(resp<span style="color:#f92672">.</span>text, <span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">html.parser</span><span style="color:#e6db74">&#39;</span>)
tars <span style="color:#f92672">=</span> soup<span style="color:#f92672">.</span>find_all(class_<span style="color:#f92672">=</span><span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">info</span><span style="color:#e6db74">&#39;</span>)
</code></pre></div><p>这里我们要注意的是<code>find_all</code>返回的是一个列表(更准确的叫法是bs4.element.ResultSet对象), 其中每一项即是一部电影的信息。<br>
我们进一步分析发现, 电影名称所在字段为<code>&lt;span class=&quot;title&quot;&gt;</code>的地方, 于是我们对其进行提取:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">title <span style="color:#f92672">=</span> tars[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>find(class_<span style="color:#f92672">=</span><span style="color:#e6db74"></span><span style="color:#e6db74">&#39;</span><span style="color:#e6db74">title</span><span style="color:#e6db74">&#39;</span>)<span style="color:#f92672">.</span>get_text()
</code></pre></div><p>用类似方法可以找到其它我们感兴趣的信息。</p>
<h3 id="最终程序-">最终程序</h3>
<p>最终我们整理一下思路:</p>
<ul>
<li>定义一个函数<code>get_movies(url, headers)</code>来实现对给定页面的信息进行提取</li>
<li>找到网址规律来多次调用上面的函数, 将得到的结果进行合并</li>
<li>将最终结果进行保存</li>
</ul>
<p>最终程序如下:<br>
<a href="/files/douban_top250.py">最终程序</a></p>


</div>
</article>
</main>


<aside class="sidebar layout__second-sidebar">
<section>
<h4 class="menu"><a href="/blogs/" class="active" aria-current="page">My Blogs</a></h4>
<ul class="menu">
<li><a href="/blogs/%E4%B8%80%E4%B8%AA%E6%97%A0%E8%81%8A%E7%9A%84c&#43;&#43;%E6%B5%8B%E8%AF%95/">一个无聊的C&#43;&#43;测试</a></li>
<li><a href="/blogs/msys2%E4%B8%AD%E7%94%A8gcc%E7%BC%96%E8%AF%91%E5%8A%A8%E6%80%81%E5%BA%93%E4%B8%8E%E9%9D%99%E6%80%81%E5%BA%93/">MSYS2中用GCC编译动态库与静态库</a></li>
<li><a href="/blogs/c&#43;&#43;%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%96%87%E4%BB%B6%E5%AD%97%E7%AC%A6%E4%B8%B2/">C&#43;&#43;学习笔记(输入输出，文件，字符串)</a></li>
<li><a href="/blogs/python%E7%88%AC%E8%99%AB%E5%88%9D%E6%8E%A2/" class="active" aria-current="page">Python爬虫初探--爬取豆瓣电影TOP250</a></li>
<li><a href="/blogs/java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E5%9F%BA%E7%A1%80%E7%AF%87/">Java学习笔记(基础篇)</a></li>
<li><a href="/blogs/%E8%AE%B0%E6%9F%90%E7%BD%91%E6%98%93%E6%A0%A1%E6%8B%9B%E7%AC%94%E8%AF%95%E9%A2%98/">记某网易校招笔试题</a></li>
<li><a href="/blogs/misc/%E5%9C%A8html%E4%B8%AD%E6%98%BE%E7%A4%BAlatex%E5%85%AC%E5%BC%8F/">使用MathJax在HTML中显示LaTeX公式</a></li>
<li><a href="/blogs/2019%E9%98%BF%E9%87%8C%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E6%B5%8B%E8%AF%95-%E5%85%89%E6%98%8E%E5%B0%8F%E5%AD%A6%E6%8E%A5%E5%8A%9B%E8%B5%9B%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%982/">2019阿里校招编程测试, 光明小学接力赛路径问题(2)</a></li>
<li><a href="/blogs/2019%E9%98%BF%E9%87%8C%E6%A0%A1%E6%8B%9B%E7%BC%96%E7%A8%8B%E6%B5%8B%E8%AF%95-%E5%85%89%E6%98%8E%E5%B0%8F%E5%AD%A6%E6%8E%A5%E5%8A%9B%E8%B5%9B%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%981/">2019阿里校招编程测试, 光明小学接力赛路径问题(1)</a></li>
<li><a href="/blogs/misc/msys2%E9%85%8D%E7%BD%AE/">msys2配置</a></li>
<li><a href="/blogs/misc/vultrvpsfreefilesync%E6%90%AD%E5%BB%BA%E8%BF%9C%E7%A8%8B%E5%90%8C%E6%AD%A5%E7%B3%BB%E7%BB%9F/">Vultr VPS &#43; FreeFileSync搭建远程同步系统</a></li>
</ul>
</section>
</aside>
<footer class="footer layout__footer">
<p><span>© Manfredo的主页</span></p>


</footer>

</div>
</body>
</html>
